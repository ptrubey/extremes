{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c3a4b8",
   "metadata": {},
   "source": [
    "**Goal: Variational Inference on parameters of Dirichlet distribution**\n",
    "\n",
    "Model:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_i &\\sim \\text{ProjGamma}_p(Y\\mid\\alpha)\\\\\n",
    "\\log\\alpha &\\sim \\text{MVNormal}(\\log\\alpha\\mid \\log(0.5), I_d)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf59a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "from numpy.random import gamma\n",
    "\n",
    "from tfprojgamma import ProjectedGamma\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1032f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.94761907 0.62279234 0.68411215 0.34912511 4.2482095 ]\n"
     ]
    }
   ],
   "source": [
    "# Set up shape parameters\n",
    "alpha_true = gamma(size = 5, shape = 1.5)\n",
    "print(alpha_true)\n",
    "dist1 = ProjectedGamma(alpha_true, 10)\n",
    "Yp    = tf.cast(dist1.sample(200), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd123399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior shape parameters\n",
    "log_alpha_0 = tf.ones(5, dtype = tf.float32) * np.log(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100c29c",
   "metadata": {},
   "source": [
    "**Define the Joint Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3954925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "def generative_model(log_alpha_0, n_samples):\n",
    "    log_alpha = yield tfd.JointDistributionCoroutine.Root(\n",
    "        tfd.MultivariateNormalDiag(\n",
    "            loc = log_alpha_0, scale_diag = tf.ones(5, dtype = tf.float32), name = 'log_alpha'\n",
    "            ),\n",
    "        )\n",
    "    Yp = yield tfd.Sample(\n",
    "        ProjectedGamma(concentration = tf.exp(log_alpha) * tf.ones((n_samples, 5), dtype = tf.float32)),\n",
    "        name = 'Yp',\n",
    "        )\n",
    "\n",
    "model_joint = tfd.JointDistributionCoroutineAutoBatched(\n",
    "    lambda: generative_model(log_alpha_0, 200),\n",
    "    )\n",
    "\n",
    "model_joint_log_prob = lambda log_alpha: model_joint.log_prob(log_alpha, Yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd408e",
   "metadata": {},
   "source": [
    "**Verifying the structure of the joint model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8caffad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.JointDistributionCoroutineAutoBatched 'JointDistributionCoroutineAutoBatched' batch_shape=[] event_shape=StructTuple(\n",
       "  log_alpha=[5],\n",
       "  Yp=[200, 5]\n",
       ") dtype=StructTuple(\n",
       "  log_alpha=float32,\n",
       "  Yp=float32\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_joint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cbe8a6",
   "metadata": {},
   "source": [
    "**Mean Field Variational Bayes -- Independence between columns**\n",
    "$$\n",
    "\\log\\alpha \\sim \\prod_{\\ell = 1}^d\\text{Normal}(\\log\\alpha_{\\ell} \\mid \\mu_{q\\ell}, \\sigma_{q\\ell})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebfdfa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([-163.42444,  393.58337,  296.38065,  527.06805, -194.55045],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([ 84.23479 , 691.3565  , 537.5379  , 729.03815 ,  68.810196],\n",
      "      dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "q_mu = tf.Variable(log_alpha_0, dtype = tf.float32)\n",
    "q_scale = tfp.util.TransformedVariable(np.ones(5), tfb.Exp(), dtype = tf.float32)\n",
    "\n",
    "surrogate_posterior = tfd.MultivariateNormalDiag(loc = q_mu, scale_diag = q_scale, name = 'surrogate 1')\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "    samples = surrogate_posterior.sample(100)\n",
    "    neg_elbo = -tf.reduce_mean(model_joint_log_prob(samples) - surrogate_posterior.log_prob(samples))\n",
    "print(g.gradient(neg_elbo, surrogate_posterior.trainable_variables)) # exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20505faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3.9614034 0.5935092 0.6732101 0.3893673 4.068376 ], shape=(5,), dtype=float32)\n",
      "tf.Tensor([0.00178767 0.00397885 0.00379829 0.00435149 0.00177991], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "path = tfp.vi.fit_surrogate_posterior(\n",
    "    target_log_prob_fn = model_joint_log_prob,\n",
    "    surrogate_posterior = surrogate_posterior,\n",
    "    optimizer = tf.optimizers.Adam(.2),\n",
    "    num_steps = 1000,\n",
    "    sample_size = 500,\n",
    "    )\n",
    "\n",
    "print(tf.exp(q_mu)) # This appears to have worked; the values end in *rougly* the right place.\n",
    "print(q_scale**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240bcd0",
   "metadata": {},
   "source": [
    "**Gaussian Variational Bayes -- Dependence Between Columns**\n",
    "$$\n",
    "\\log\\alpha \\sim \\text{MVNormal}(\\log\\alpha \\mid \\mu_q, \\Sigma_q)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6063356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([-167.1391 ,  843.6687 ,  565.7811 , 1421.4977 , -153.87805],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(15,), dtype=float32, numpy=\n",
      "array([ 338.59695 , -125.0202  ,   26.117214,  -40.666622, -135.07663 ,\n",
      "        171.36061 , 2645.6987  , -998.0686  , -920.1034  ,  452.4206  ,\n",
      "        167.13881 , 1390.3918  , 1060.2035  ,   68.15751 ,  274.95932 ],\n",
      "      dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# New Style: Make the variational Parameters\n",
    "q_nu = tf.Variable(tf.zeros(5, dtype = tf.float32), name = 'Mu Surrogate (mean of log alpha)')\n",
    "cholbijector = tfb.FillScaleTriL(diag_bijector = tfb.Exp())\n",
    "q_Lu = tfp.util.TransformedVariable(tf.eye(5), bijector = cholbijector)\n",
    "\n",
    "surrogate_posterior_mvnorm = tfd.MultivariateNormalTriL(loc = q_nu, scale_tril = q_Lu)\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "    samples = surrogate_posterior_mvnorm.sample(100)\n",
    "    neg_elbo = -tf.reduce_mean(model_joint_log_prob(samples) - surrogate_posterior_mvnorm.log_prob(samples))\n",
    "print(g.gradient(neg_elbo, surrogate_posterior_mvnorm.trainable_variables)) # Exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a867e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3.8994887  0.5955216  0.6662088  0.38724408 4.1442165 ], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "path_mvnorm = tfp.vi.fit_surrogate_posterior(\n",
    "    target_log_prob_fn = model_joint_log_prob,\n",
    "    surrogate_posterior = surrogate_posterior_mvnorm,\n",
    "    optimizer = tf.optimizers.Adam(.2),\n",
    "    num_steps = 1000,\n",
    "    sample_size = 500,\n",
    "    )\n",
    "print(tf.exp(q_nu)) # This gives the same basic response as previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf10016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q_Lu.numpy() @ q_Lu.numpy().T > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1152591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00384308, 0.00172062, 0.00245882, 0.00183036, 0.00274806],\n",
       "       [0.00172062, 0.00478812, 0.001474  , 0.00106701, 0.00123463],\n",
       "       [0.00245882, 0.001474  , 0.00548552, 0.00076655, 0.00180139],\n",
       "       [0.00183036, 0.00106701, 0.00076655, 0.00534088, 0.00147093],\n",
       "       [0.00274806, 0.00123463, 0.00180139, 0.00147093, 0.00374892]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q_Lu.numpy() @ q_Lu.numpy().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0653197",
   "metadata": {},
   "source": [
    "I guess it makes some sense that the posterior covariance between parameters of the Dirichlet would be positive, despite the covariance between *values* of the Dirichlet being negative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
