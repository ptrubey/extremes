{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428fd6d3",
   "metadata": {},
   "source": [
    "## A Simple Variational Approximation for the Shape Parameter of a Gamma Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f02971",
   "metadata": {},
   "source": [
    "Let\n",
    "$$\n",
    "y_i \\sim \\mathcal{G}(y\\mid\\alpha,1),\\hspace{1cm}\\alpha \\sim \\mathcal{G}(\\alpha \\mid a, b)\n",
    "$$\n",
    "such that\n",
    "$$\n",
    "f(y,\\alpha) \\propto \\prod_{i = 1}^n\\mathcal{G}(y_i\\mid\\alpha,1)\\times\\mathcal{G}(\\alpha\\mid a,b)\n",
    "$$\n",
    "and assume a variational model such that $\\lambda = \\log(\\alpha)$, and\n",
    "$$\n",
    "\\lambda \\sim \\mathcal{N}(\\lambda\\mid\\mu,\\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185d2dc",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "f(y,\\lambda) &= \\prod_{i = 1}^n \\left[\\frac{1^{e^{\\lambda}}}{\\Gamma(e^{\\lambda})}y_i^{e^{\\lambda} - 1}e^{-be^{\\lambda}}\\right]\\times \\frac{b^a}{\\Gamma(a)}e^{\\lambda a}e^{-be^{\\lambda}}\\\\\n",
    "&= \\frac{1}{\\Gamma^n(e^{\\lambda})}\\left(\\prod_{i = 1}^n y_i\\right)^{e^{\\lambda} - 1}e^{-\\sum_{i = 1}^n y_i}\\frac{b^a}{\\Gamma(a)}e^{a\\lambda}e^{-be^{\\lambda}}\\\\\n",
    "\\log f(y,\\lambda) &= -n\\log\\Gamma(e^{\\lambda}) - (e^{\\lambda} - 1)\\sum_{i = 1}^n\\log(y_i) - \\sum_{i = 1}^n y_i + a\\log(b) - \\log\\Gamma(a) + a\\lambda - be^{\\lambda}\\\\\n",
    "&= -n\\log\\Gamma(e^{\\lambda}) - \\left(\\sum_{i = 1}^n\\log(y_i)\\right)(e^{\\lambda} - 1) + \\sum_{i = 1}^n y_i + a\\log(b) - \\log\\Gamma(a) + a\\lambda - be^{\\lambda}\\\\\n",
    "&= -n\\log\\Gamma(e^{\\lambda}) - \\left(\\sum_{i = 1}^n\\log(y_i) + b\\right)e^{\\lambda} + a\\lambda + C_{f}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db53510e",
   "metadata": {},
   "source": [
    "Where $C$ denotes a constant with respect to $\\lambda$.  To unbound $\\sigma$, let $\\tau = \\log\\sigma$.  Then do the same for $q_{\\mu,\\tau}(\\lambda)$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "q_{\\mu,\\tau}(\\lambda) &= \\frac{1}{\\sqrt{2\\pi}e^{\\tau}}\\exp\\left\\lbrace-\\frac{1}{2e^{2\\tau}}(\\lambda - \\mu)^2\\right\\rbrace\\\\\n",
    "\\log q_{\\mu,\\tau}(\\lambda) &= -\\frac{1}{2}\\log(2\\pi) - \\tau - \\frac{1}{2}e^{-2\\tau}(\\lambda - \\mu)^2\\\\\n",
    "&= - \\tau - \\frac{1}{2}e^{-2\\tau}(\\lambda - \\mu)^2 + C_q\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5919fb",
   "metadata": {},
   "source": [
    "So our objective function, $h_{\\mu,\\tau}(\\lambda)$ is then $\\log f(y,\\lambda) - \\log q_{\\mu,\\tau}(\\lambda)$\n",
    "\n",
    "$$\n",
    "h_{\\mu,\\tau}(\\lambda) = -n\\log\\Gamma(e^{\\lambda}) - \\left(\\sum_{i = 1}^n\\log(y_i) + b\\right)e^{\\lambda} + a\\lambda + \\tau + \\frac{1}{2}e^{-2\\tau}(\\lambda - \\mu)^2 + C\n",
    "$$\n",
    "Then, taking the derivative with respect to $\\lambda$, we get:\n",
    "$$\n",
    "\\Delta_{\\lambda}h_{\\mu,\\tau}(\\lambda) = -ne^{\\lambda}\\Psi(e^{\\lambda}) - \\left(\\sum_{i = 1}^n\\log(y_i) + b\\right)e^{\\lambda} + a - e^{-2\\tau}(\\lambda - \\mu)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42388a60",
   "metadata": {},
   "source": [
    "Finally, letting $\\lambda = g(\\mu,\\tau,\\varepsilon)$ where $\\varepsilon \\sim \\mathcal{N}(0,1)$, the reparameterization gradient estimator is reached as\n",
    "\n",
    "$$\n",
    "\\Delta_{\\mu,\\tau} \\mathcal{L}(\\mu,\\tau) = \\text{E}_{\\varepsilon}\\left[\\Delta_{\\mu,\\tau}g(\\mu,\\tau,\\varepsilon)^T\\Delta_{\\lambda}h_{\\mu,\\tau}(\\lambda)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7d581",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996902ba",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d311a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as skl\n",
    "\n",
    "from scipy.special import digamma\n",
    "\n",
    "true_alpha = 3.5\n",
    "sample_size = 100\n",
    "\n",
    "# data generation\n",
    "Y = np.random.gamma(shape = true_alpha, scale = 1, size = sample_size)\n",
    "sum_log_y = np.log(Y).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd27ea8",
   "metadata": {},
   "source": [
    "Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_h(epsilon, mu, tau, a, b):\n",
    "    lam = np.exp(tau) * epsilon + mu\n",
    "    alp = np.exp(lam)\n",
    "    \n",
    "    out = np.zeros(epsilon.shape[0])\n",
    "    out -= sample_size * alp * digamma(alp)\n",
    "    out -= (sum_log_y + b) * alp\n",
    "    out += a\n",
    "    out -= np.exp(-2 * tau) * (lam - mu)\n",
    "    return out.reshape((-1,1))\n",
    "\n",
    "def delta_g(epsilon, mu, tau):\n",
    "    return np.array((1, np.exp(tau) * epsilon)).reshape((1, -1))\n",
    "\n",
    "def objective(args):\n",
    "    epsilon = np.random.normal(20)\n",
    "    mu, tau = args\n",
    "    out = delta_g(epsilon, mu, tau) * delta_h(epsilon, mu, tau)\n",
    "    return out.mean(axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
